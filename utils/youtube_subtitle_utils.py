# import yt_dlp
# import requests

# def get_subtitle_text(youtube_url: str, lang="ko"):
#     ydl_opts = {'quiet': True}

#     with yt_dlp.YoutubeDL(ydl_opts) as ydl:
#         info = ydl.extract_info(youtube_url, download=False)
#         subtitles = info.get("subtitles", {})

#         # ìš”ì²­í•œ ì–¸ì–´ì˜ ìë§‰ì´ ìˆëŠ”ì§€ í™•ì¸
#         if lang not in subtitles:
#             print(f"âš ï¸ '{lang}' ìë§‰ì´ ì—†ìŠµë‹ˆë‹¤.")
#             return None

#         # ìë§‰ URL ê°€ì ¸ì˜¤ê¸°
#         subtitle_url = subtitles[lang][0]['url']

#         # ìë§‰ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (XML ë˜ëŠ” SRT í˜•ì‹)
#         response = requests.get(subtitle_url)
#         subtitle_text = response.text

#         print(f"ğŸ“Œ {lang} ìë§‰ ë¯¸ë¦¬ë³´ê¸°:")
#         print(subtitle_text[:500])  # ìë§‰ ì¼ë¶€ë§Œ ì¶œë ¥

#         return subtitle_text

# # # standalone í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ (ì›í•˜ëŠ” ê²½ìš°)
# # if __name__ == '__main__':
# #     youtube_url = "https://www.youtube.com/watch?v=28kn2IQEWRk"
# #     subtitle_text = get_subtitle_text(youtube_url, lang="ko")
# #     print(subtitle_text)

"""
YouTube ìë§‰ì„ ë‚´ë ¤ë°›ì•„ start / dur / text ì •ë³´ë¥¼
JSON ìœ¼ë¡œ ì €ì¥í•˜ê³  (captions, file_path) ë¥¼ ë°˜í™˜í•œë‹¤.
"""
from __future__ import annotations

import os
import re
import json
import time
import requests
import xml.etree.ElementTree as ET
from html import unescape
from typing import List, Dict, Tuple, Optional

import yt_dlp
from utils.logging_utils import logger

# ---------------------------------------------------------------------
# ê³µí†µ ì„¤ì •
# ---------------------------------------------------------------------
_SUBTITLE_DIR = os.path.join("output", "subtitles")
os.makedirs(_SUBTITLE_DIR, exist_ok=True)

# ---------------------------------------------------------------------
# srv3 / ttml íŒŒì‹±
# ---------------------------------------------------------------------
def _parse_srv3(xml_text: str) -> List[Dict]:
    """<text start="â€¦" dur="â€¦"> í˜•ì‹ì˜ XML(srv3/ttml) íŒŒì‹±."""
    try:
        root = ET.fromstring(xml_text)
    except ET.ParseError:
        logger.warning("[XML íŒŒì‹± ì‹¤íŒ¨] srv3/ttml í¬ë§· ì•„ë‹˜")
        return []

    captions: List[Dict] = []
    for elem in root.findall(".//text"):
        try:
            start = float(elem.attrib.get("start", 0))
            dur = float(elem.attrib.get("dur", 0))
            txt = unescape(elem.text or "").replace("\n", " ").strip()
            captions.append({"start": start, "dur": dur, "text": txt})
        except ValueError:
            continue
    return captions

# ---------------------------------------------------------------------
# VTT íŒŒì‹±
# ---------------------------------------------------------------------
_VTT_TIMESTAMP_RE = re.compile(
    r"(?P<h>\d{2}):(?P<m>\d{2}):(?P<s>\d{2})\.(?P<ms>\d{3})"
)


def _vtt_ts_to_sec(ts: str) -> float:
    m = _VTT_TIMESTAMP_RE.search(ts)
    if not m:
        return 0.0
    h, m_, s, ms = map(int, m.groups())
    return h * 3600 + m_ * 60 + s + ms / 1000


def _parse_vtt(vtt_text: str) -> List[Dict]:
    lines = [l.rstrip("\r") for l in vtt_text.splitlines()]
    captions: List[Dict] = []
    cur: Optional[Dict] = None

    for ln in lines:
        if "-->" in ln and _VTT_TIMESTAMP_RE.search(ln):
            if cur:  # ì´ì „ ìº¡ì…˜ push
                captions.append(cur)
            ts_from, ts_to = [t.strip() for t in ln.split("-->")]
            cur = {
                "start": _vtt_ts_to_sec(ts_from),
                "dur": None,
                "text": "",
            }
            end_time = _vtt_ts_to_sec(ts_to)
            if end_time > cur["start"]:
                cur["dur"] = end_time - cur["start"]
        elif ln.strip() == "":
            if cur and cur["text"]:
                captions.append(cur)
                cur = None
        else:
            # ìë§‰ í…ìŠ¤íŠ¸ ë¼ì¸
            if cur is not None:
                cur["text"] += (ln + " ")

    # íŒŒì¼ ë ì²˜ë¦¬
    if cur and cur["text"]:
        captions.append(cur)

    # dur ì—†ëŠ” ìº¡ì…˜ ë³´ì • (ë‹¤ìŒ ìº¡ì…˜ ì‹œì‘ - í˜„ì¬ ì‹œì‘)
    for i in range(len(captions) - 1):
        if captions[i]["dur"] is None:
            captions[i]["dur"] = (
                captions[i + 1]["start"] - captions[i]["start"]
            )
    return captions

# ---------------------------------------------------------------------
# JSON ì €ì¥
# ---------------------------------------------------------------------
def _save_json(info: dict, lang: str, captions: List[Dict]) -> str:
    youtube_id = info.get("id", "unknown")
    title = info.get("title") or ""
    ts = int(time.time())
    fname = f"{youtube_id}_{ts}.json"
    fpath = os.path.join(_SUBTITLE_DIR, fname)

    with open(fpath, "w", encoding="utf-8") as f:
        json.dump(
            {
                "youtube_id": youtube_id,
                "title": title,
                "lang": lang,
                "captions": captions,
            },
            f,
            ensure_ascii=False,
            indent=2,
        )

    logger.info(f"[ìë§‰ ì €ì¥ ì™„ë£Œ] {fpath}")
    return os.path.abspath(fpath)

# ---------------------------------------------------------------------
# ë©”ì¸ í•¨ìˆ˜
# ---------------------------------------------------------------------
def get_subtitle_with_timing(
    youtube_url: str,
    lang: str = "ko",
) -> Tuple[Optional[List[Dict]], Optional[str]]:
    """
    (captions, file_path) ë°˜í™˜.
    ìë§‰ íŠ¸ë™ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•´, íŒŒì‹± ì„±ê³µ ì‹œ ì¦‰ì‹œ ë°˜í™˜.
    """
    ydl_opts = {"quiet": True}
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(youtube_url, download=False)

    # ---------- íŠ¸ë™ í›„ë³´ ìˆ˜ì§‘ ----------
    def _collect_tracks(source_dict: dict) -> List[dict]:
        tracks: List[dict] = []
        for code, lst in source_dict.items():
            # ìš”ì²­ ì–¸ì–´ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ê±°ë‚˜, 'ko-KR' ì²˜ëŸ¼ ì ‘ë‘ì‚¬ê°€ ê°™ì€ ê²½ìš° í¬í•¨
            if code == lang or code.startswith(f"{lang}-") or code.split("-")[0] == lang:
                tracks.extend(lst)
        return tracks

    tracks = (
        _collect_tracks(info.get("subtitles", {}))
        + _collect_tracks(info.get("automatic_captions", {}))
    )
    if not tracks:
        logger.warning(f"[ìë§‰ íŠ¸ë™ ì—†ìŒ] {lang=} {youtube_url=}")
        return None, None

    # ---------- í™•ì¥ì ìš°ì„ ìˆœìœ„ ----------
    ext_priority = {"srv3": 0, "ttml": 1, "vtt": 2}
    tracks.sort(key=lambda t: ext_priority.get(t.get("ext"), 99))

    # ---------- ê° íŠ¸ë™ ì‹œë„ ----------
    for t in tracks:
        url = t["url"]
        ext = t.get("ext")
        # srv3 ê°•ì œ íŒŒë¼ë¯¸í„°
        if ext == "srv3" and "fmt=" not in url:
            url += "&fmt=srv3"

        logger.info(f"[ìë§‰ ë‹¤ìš´ë¡œë“œ] ext={ext} url={url}")
        try:
            res = requests.get(url, timeout=10)
            res.raise_for_status()
            raw = res.text
        except Exception:
            logger.error("[ìë§‰ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨]", exc_info=True)
            continue

        # --- íŒŒì‹± ---
        if ext in ("srv3", "ttml") or "<text" in raw[:200]:
            captions = _parse_srv3(raw)
        elif ext == "vtt" or raw.lstrip().startswith("WEBVTT"):
            captions = _parse_vtt(raw)
        else:
            logger.warning(f"[ì•Œ ìˆ˜ ì—†ëŠ” í¬ë§·] ext={ext}")
            captions = []

        # íŒŒì‹± ì„±ê³µ ì—¬ë¶€ í™•ì¸
        if captions:
            file_path = _save_json(info, lang, captions)
            return captions, file_path
        else:
            logger.warning(f"[íŒŒì‹± ì‹¤íŒ¨] ext={ext} â†’ ë‹¤ìŒ íŠ¸ë™ ì‹œë„")

    # ëª¨ë“  íŠ¸ë™ íŒŒì‹± ì‹¤íŒ¨
    logger.error("[ìë§‰ íŒŒì‹± ì‹¤íŒ¨] ëª¨ë“  íŠ¸ë™ì—ì„œ captions ì¶”ì¶œ ë¶ˆê°€")
    return None, None
